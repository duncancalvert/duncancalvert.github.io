<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://duncancalvert.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://duncancalvert.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-07-29T19:13:09+00:00</updated><id>https://duncancalvert.github.io/feed.xml</id><title type="html">blank</title><subtitle>My simple, whitespace theme portfolio. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">The Platonic Representation Hypothesis</title><link href="https://duncancalvert.github.io/blog/2024/the_platonic_representation_hypothesis/" rel="alternate" type="text/html" title="The Platonic Representation Hypothesis"/><published>2024-05-29T05:36:10+00:00</published><updated>2024-05-29T05:36:10+00:00</updated><id>https://duncancalvert.github.io/blog/2024/the_platonic_representation_hypothesis</id><content type="html" xml:base="https://duncancalvert.github.io/blog/2024/the_platonic_representation_hypothesis/"><![CDATA[<p>Amidst the buzz around GPT-4o and Google I/O, it was easy to miss this fascinating philosophical paper from MIT. ‚Äú<a href="https://phillipi.github.io/prh/">The Platonic Representation Hypothesis</a>,‚Äù argues that AI models are converging towards a shared ‚Äúreality‚Äù. As they grow in size, their data representations across different modalities (images, text, etc.) become more aligned, echoing Plato‚Äôs ideal forms.</p> <p>üîç Highlights:</p> <p>‚Ä¢ Unified Representations: Larger models show more alignment, suggesting a common underlying reality and statistical model.</p> <p>‚Ä¢ Multimodal Efficiency: Combining data types boosts model performance and convergence.</p> <p>‚Ä¢ Revolutionary Potential: Easier cross-modal translation and adaptation could transform AI applications.</p>]]></content><author><name></name></author><category term="data-science"/><category term="AI"/><category term="MachineLearning"/><category term="DeepLearning"/><category term="MIT"/><category term="Research"/><category term="NeuralNetworks"/><summary type="html"><![CDATA[Exploring world representations in neural networks]]></summary></entry><entry><title type="html">Building Efficient Baselines in Minutes: EDA and Classification in Google Colab</title><link href="https://duncancalvert.github.io/blog/2023/building-efficient-baselines-in-minutes-eda-and-classification-in-google-colab/" rel="alternate" type="text/html" title="Building Efficient Baselines in Minutes: EDA and Classification in Google Colab"/><published>2023-11-26T23:23:35+00:00</published><updated>2023-11-26T23:23:35+00:00</updated><id>https://duncancalvert.github.io/blog/2023/building-efficient-baselines-in-minutes-eda-and-classification-in-google-colab</id><content type="html" xml:base="https://duncancalvert.github.io/blog/2023/building-efficient-baselines-in-minutes-eda-and-classification-in-google-colab/"><![CDATA[]]></content><author><name></name></author></entry></feed>