<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://duncancalvert.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://duncancalvert.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-05-31T02:44:23+00:00</updated><id>https://duncancalvert.github.io/feed.xml</id><title type="html">blank</title><subtitle>My simple, whitespace theme portfolio. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">AI Agent Memory</title><link href="https://duncancalvert.github.io/blog/2025/ai_agent_memory/" rel="alternate" type="text/html" title="AI Agent Memory"/><published>2025-05-30T18:14:10+00:00</published><updated>2025-05-30T18:14:10+00:00</updated><id>https://duncancalvert.github.io/blog/2025/ai_agent_memory</id><content type="html" xml:base="https://duncancalvert.github.io/blog/2025/ai_agent_memory/"><![CDATA[<p><br/></p> <p style="text-align: center;"> <em>"What we call the present is given shape by an accumulation of memories."</em><br/> ‚Äî Haruki Murakami </p> <p><br/></p> <h2 id="what-is-ai-agent-memory">What is AI Agent Memory</h2> <ul> <li>An agent‚Äôs ‚Äúmemory‚Äù is data that is not provided by the user in their prompt, but is retrieved and appended to the reasoning process via runtime calls.</li> <li>Agent memory encompasses a diverse set of references and can include everything from past user interactions, previous agent actions, external knowledge bases, system prompts, guardrails, etc.</li> <li>The additional context and knowledge provided by memory helps the agent to better conceptualize the request, plan, and then answer the user or take an action.</li> </ul> <div style="text-align: center;"> <img src="assets/img/agent_memory_post/agent_memory.png" alt="Agent Memory Diagram" style="max-width: 100%; height: auto;"/> <p style="font-size: 0.9em; font-style: italic; color: #555;">[Cognitive Architectures for Language Agents](https://arxiv.org/pdf/2309.02427)</p> </div> <hr/> <h2 id="long-term-agent-memory-types">Long-Term Agent Memory Types</h2> <ol> <li><strong>Episodic:</strong> this type of memory contains past agent interactions and agent action logs. For example, if you asked a chatbot to ‚Äúrepeat the last action that it took in a previous session,‚Äù it could use episodic memory to complete this request.</li> <li><strong>Semantic:</strong> this type of memory contains any knowledge the agent should have about itself, or any grounding information stored in knowledge bases that the agent has access to. For example, a vector store in a RAG application is semantic memory.</li> <li><strong>Procedural:</strong> this type of memory contains system information like the system prompt, metadata on available tools, guardrails, etc. It is usually stored and versioned in Git or prompt registry tools.</li> </ol> <hr/> <h2 id="short-term-agent-memory">Short-Term Agent Memory</h2> <ul> <li>Any of the above long-term memory types that is pulled during runtime is called ‚Äúshort-term memory‚Äù or ‚Äúworking memory‚Äù.</li> <li>This short-term memory is added to the user prompt and passed to the LLM with the aim of boosting performance</li> <li>Any intermediate reasoning steps/action history of the current session is also considered short-term memory when in-use.</li> </ul> <hr/> <h3 id="references">References</h3> <ul> <li><a href="https://arxiv.org/pdf/2309.02427">Cognitive Architectures for Language Agents</a></li> </ul>]]></content><author><name></name></author><category term="data-science"/><category term="AI"/><category term="Research"/><category term="Agents"/><summary type="html"><![CDATA[Demystifying the different types of AI agent memory]]></summary></entry><entry><title type="html">The Roadmap to AI Technical Product Manager</title><link href="https://duncancalvert.github.io/blog/2025/the_roadmap_to_ai_tpm/" rel="alternate" type="text/html" title="The Roadmap to AI Technical Product Manager"/><published>2025-05-18T16:04:10+00:00</published><updated>2025-05-18T16:04:10+00:00</updated><id>https://duncancalvert.github.io/blog/2025/the_roadmap_to_ai_tpm</id><content type="html" xml:base="https://duncancalvert.github.io/blog/2025/the_roadmap_to_ai_tpm/"><![CDATA[<h2 id="what-makes-an-ai-technical-product-manager-different-than-a-normal-tpm">What Makes an AI Technical Product Manager Different Than a Normal TPM</h2> <p>The rise of AI and Agentic frameworks have redefined the landscape of product development and the role of a TPM. A traditional TPM focuses on building scalable systems, ensures alignment of engineering execution with product goals, and translates business needs into technical specs. In contrast, an AI TPM guides the development of probabilistic, data-dependent products where performance can vary across inputs, and success isn‚Äôt measured in ‚Äúfeatures shipped‚Äù but in model quality, inference efficiency, and real-world generalization.</p> <p>AI systems introduce new kinds of architecture concerns: model training pipelines, feature stores, real-time inference latency, versioning of data/models, and monitoring for drift and degradation. The AI TPM must orchestrate this stack while aligning with model scientists, ML engineers, infra teams, data SMEs, end users, and compliance stakeholders. They are responsible not just for what gets built, but how learning systems are trained, deployed, scaled, and governed. AI TPMs live at the intersection of infrastructure, research, and imperfect systems.</p> <hr/> <h2 id="skill-sets">Skill Sets</h2> <p><br/></p> <h3 id="ai-product-skills">AI Product Skills</h3> <ul> <li><ins>AI product sense</ins>: understand what can, and importantly cannot, be solved by AI (i.e. AI is not a silver bullet, many processes and products are better served with non-AI solutions)</li> <li><ins>AI experiment design</ins>: practice iterative hypothesis testing with quantitative evaluation. Lead with A/B test, user interviews, and user feedback loops wherever possible</li> <li><ins>Market insight</ins>: build a deep understanding of the AI market, its competitive landscape, and emerging trends</li> <li><ins>User Journeys</ins>: define clear user journeys that align to a strategic AI product philosophy and north star metric</li> </ul> <h3 id="traditional-data-science-expertise">Traditional Data Science Expertise</h3> <ul> <li><ins>AI models</ins>: understand what the difference is between Random Forest, SVM, and KNN and when to use one over the other on a problem.</li> <li><ins>AI evaluation metrics</ins>: undestand the right metrics for each model and use case.</li> <li>Model Development Lifecycle (MDLC):</li> <li>Machine Learning Operations (MLOps) processes and principles</li> <li>Python (OOP principles, Pandas, NumPy, Jupyter)</li> <li>Deep Learning (PyTorch/TensorFlow/Non-Transformer Neural Networks) <ul> <li><a href="https://www.coursera.org/specializations/deep-learning">(Class) Deep Learning Specialisation by Andrew Ng</a></li> <li><a href="https://www.deeplearningbook.org/">(Book) Deep Learning by Ian Goodfellow</a></li> </ul> </li> <li>SQL</li> <li>Apache Spark/PySpark</li> <li>Data Warehouse/Data Lakehouse <ul> <li>Databricks</li> <li>Snowflake</li> <li>GCP BigQuery</li> </ul> </li> </ul> <h3 id="gen-ai-expertise">Gen AI Expertise</h3> <ul> <li>Vector databases (Pinecone, Weaviate, Chroma, Elasticsearch)</li> <li>Model garden APIs (Azure, GCP, AWS, OpenAI)</li> <li>Models <ul> <li>Transformer model architecture <ul> <li><a href="https://www.manning.com/books/build-a-large-language-model-from-scratch">(Book) Build a Large Language Model (From Scratch) by Sebastian Raschka</a></li> <li><a href="https://www.youtube.com/watch?v=7xTGNNLPyMI&amp;ab_channel=AndrejKarpathy">(Video) Deep Dive into LLMs like ChatGPT by Andrej Karpathy</a></li> <li><a href="https://arxiv.org/abs/1706.03762">(Paper) Attention is All You Need</a></li> <li><a href="https://www.youtube.com/watch?v=9vM4p9NN0Ts&amp;ab_channel=StanfordOnline">(Class) Stanford CS229 - Machine Learning - Building Large Language Models (LLMs)</a></li> </ul> </li> <li>Diffusion model architecture</li> <li>GAN model architecture</li> </ul> </li> <li>LLM benchmarks <ul> <li><a href="https://www.latent.space/p/benchmarks-101">(Podcast Episode) AI Fundamentals: Benchmarks 101</a></li> <li><a href="https://www.latent.space/p/benchmarks-201">(Podcast Episode) Benchmarks 201: Why Leaderboards &gt; Arenas¬†¬ª LLM-as-Judge</a></li> </ul> </li> <li>LLM evaluation strategies</li> <li>Prompt Engineering <ul> <li><a href="https://platform.openai.com/docs/guides/text?api-mode=responses">(Article) OpenAI Prompting Guide</a></li> <li><a href="https://www.promptingguide.ai/">(Website) Prompt Engineering Guide by DAIR.AI</a></li> </ul> </li> <li>LLM Observability (Langfuse and LangSmith)</li> </ul> <h3 id="agentic-expertise">Agentic Expertise</h3> <ul> <li>Agent Fundamentals <ul> <li><a href="https://www.kaggle.com/whitepaper-agents">(White Paper) Google Agents White Paper by Julia Wiesinger et al.</a></li> <li><a href="https://www.kaggle.com/whitepaper-agent-companion">(White Paper) Google Agents Companion White Paper by Antonio Gulli et al.</a></li> <li><a href="https://arxiv.org/abs/2505.10468">(Paper) AI Agents vs. Agentic AI: A Conceptual Taxonomy, Applications and Challenges</a></li> <li><a href="https://arxiv.org/abs/2210.03629">(Paper) ReAct: Synergizing Reasoning and Acting in Language Models by Shunyu Yao et al.</a></li> </ul> </li> <li>Agent Evals <ul> <li><a href="https://arxiv.org/abs/2410.10934">(Paper) Agent-as-a-Judge: Evaluate Agents with Agents</a></li> </ul> </li> <li>Agent Frameworks <ul> <li>LangChain</li> <li>LangGraph <ul> <li><a href="https://www.deeplearning.ai/short-courses/ai-agents-in-langgraph/">(Class) AI Agents in LangGraph by DeepLearning.AI</a></li> </ul> </li> <li>LlamaIndex <ul> <li><a href="https://www.deeplearning.ai/short-courses/building-agentic-rag-with-llamaindex/">(Class) Building Agentic RAG with LlamaIndex by DeepLearning.AI</a></li> </ul> </li> <li>Open AI Agent SDK</li> <li>Mastra</li> </ul> </li> <li>Agent Protocols <ul> <li>Anthropic Model Context Protocol (MCP) <ul> <li><a href="https://blog.neosage.io/p/why-every-ai-builder-needs-to-understand">(Article) Why Every AI Builder Needs to Understand MCP</a></li> </ul> </li> <li>Google Agent-2-Agent (A2A)</li> </ul> </li> <li>AI Integrated Development Environments (IDE): Cursor, Windsurf, or Replit</li> <li>Agentic Design Patterns <ul> <li><a href="https://www.philschmid.de/agentic-pattern">(Article) Zero to One: Learning Agentic Patterns</a></li> <li><a href="https://www.deeplearning.ai/short-courses/ai-agentic-design-patterns-with-autogen/">(Class) AI Agentic Design Patterns with AutoGen by DeepLearning.AI</a></li> <li><a href="https://www.deeplearning.ai/short-courses/multi-ai-agent-systems-with-crewai/">(Class) Multi AI Agent Systems with crewAI by DeepLearning.AI</a></li> </ul> </li> </ul> <h3 id="general-technical-expertise">General Technical Expertise</h3> <ul> <li>Public cloud infrastructure (GCP, Azure, AWS)</li> <li>Data pipelines <ul> <li>Apache Airflow/GCP Composer</li> <li>Dataflow</li> <li>Apache Beam</li> <li>Apache Kafka</li> </ul> </li> <li>API and Backend skills <ul> <li>Develop backends with FastAPI or Flask</li> <li>Implement REST and streaming endpoints for AI services</li> <li>Design authentication and rate limiting systems</li> <li>Build WebSocket implementations for real-time AI interactions</li> </ul> </li> </ul> <h3 id="soft-skills">Soft Skills</h3> <ul> <li><ins>Stakeholder management</ins>: Adept at influencing executives and building consensus in a constantly changing and fast-paced environment.</li> <li><ins>Expert Storytelling</ins>: master product positioning and messaging. Create a proven track record of successfully positioning solutions, presentation, and public speaking for technology professionals and leaders</li> <li><ins>Product Launch Experience</ins>: build up a knowledge of what to do at different stages of the product launch cycle, and how to do it</li> <li><ins>Growth and Expansive Mindset</ins>: foster a curiosity to learn, growth mindset, and positive attitude (kind human policy)</li> </ul> <h3 id="general-product-management">General Product Management</h3> <ul> <li>Waterfall</li> <li>Agile (Scrum/Kanban)</li> <li>Continuous Integration/Continuous Delivery (CI/CD)</li> <li>DevOps and Site Reliability Engineering (SRE)</li> <li>Robust documentation</li> <li>FinOps</li> </ul> <hr/> <h2 id="newsletters-podcasts-and-people">Newsletters, Podcasts, and People</h2> <p><br/></p> <h3 id="newsletters">Newsletters</h3> <ul> <li><a href="https://thesequence.substack.com/">The Sequence</a>: A weekly series that does technical deep dives on the latest AI/ML techniques</li> <li><a href="https://www.deeplearning.ai/the-batch/">The Batch @ DeepLearning.AI</a>: a weekly deep dive from Stanford Professor Andrew Ng</li> <li><a href="https://www.deeplearning.ai/the-batch/tag/data-points/">Data Points</a></li> <li><a href="https://www.dailyzaps.com/">Daily Zaps</a>: high level tech news, not very technical</li> <li><a href="https://mlops.substack.com/">The MLOps Newsletter</a>: technical with a specific focus on MLOps</li> <li><a href="https://developers.google.com/newsletter">Google Developer Program</a>: stay up to date with the latest GCP releases</li> <li><a href="https://medium.com/towards-data-science/newsletter">The Variable</a>: a curated list of articles/tutorials from Towards Data Science, the data science channel in Medium</li> <li><a href="https://www.technologyreview.com/topic/download-newsletter/">The Download from MIT Technology Review</a>: a higher level tech news roundup</li> <li><a href="https://www.turingpost.com/">Turing Post</a></li> </ul> <h3 id="podcasts">Podcasts</h3> <ul> <li><a href="https://podcasts.apple.com/us/podcast/practical-ai/id1406537385">Practical AI by Changelog</a></li> <li><a href="https://www.youtube.com/playlist?list=PLRRoCwK1ZTNCAZXXOswpIYQqzMgT4swsI">Inference by Turing Post</a></li> <li><a href="https://www.latent.space/podcast">Latent Space: The AI Engineer Podcast</a></li> </ul> <h3 id="people-to-follow">People to Follow</h3> <ul> <li><a href="https://www.linkedin.com/in/yann-lecun/">Yann LeCun</a></li> <li>Andrej Karpathy</li> <li><a href="https://www.linkedin.com/in/fei-fei-li-4541247/">Fei-Fei Li</a></li> <li><a href="https://eugeneyan.com/subscribe">Eugene Yan</a>: ML, RecSys, LLMs, and engineering</li> </ul>]]></content><author><name></name></author><category term="data-science"/><category term="AI"/><category term="Machine_Learning"/><category term="Deep_Learning"/><category term="Research"/><category term="Neural_Networks"/><category term="Product_Management"/><category term="Agents"/><summary type="html"><![CDATA[A guide to AI upskilling for Technical Product Managers]]></summary></entry><entry><title type="html">RAG Engine Optimization: An Emerging Discipline</title><link href="https://duncancalvert.github.io/blog/2024/rag-engine-optimization-an-emerging-discipline/" rel="alternate" type="text/html" title="RAG Engine Optimization: An Emerging Discipline"/><published>2024-10-29T21:50:11+00:00</published><updated>2024-10-29T21:50:11+00:00</updated><id>https://duncancalvert.github.io/blog/2024/rag-engine-optimization-an-emerging-discipline</id><content type="html" xml:base="https://duncancalvert.github.io/blog/2024/rag-engine-optimization-an-emerging-discipline/"><![CDATA[]]></content><author><name></name></author></entry><entry><title type="html">How to Pass the Neo4j Certified Professional Exam</title><link href="https://duncancalvert.github.io/blog/2024/how-to-pass-the-neo4j-certified-professional-exam/" rel="alternate" type="text/html" title="How to Pass the Neo4j Certified Professional Exam"/><published>2024-08-04T19:52:57+00:00</published><updated>2024-08-04T19:52:57+00:00</updated><id>https://duncancalvert.github.io/blog/2024/how-to-pass-the-neo4j-certified-professional-exam</id><content type="html" xml:base="https://duncancalvert.github.io/blog/2024/how-to-pass-the-neo4j-certified-professional-exam/"><![CDATA[]]></content><author><name></name></author></entry><entry><title type="html">The Platonic Representation Hypothesis</title><link href="https://duncancalvert.github.io/blog/2024/the_platonic_representation_hypothesis/" rel="alternate" type="text/html" title="The Platonic Representation Hypothesis"/><published>2024-05-29T05:36:10+00:00</published><updated>2024-05-29T05:36:10+00:00</updated><id>https://duncancalvert.github.io/blog/2024/the_platonic_representation_hypothesis</id><content type="html" xml:base="https://duncancalvert.github.io/blog/2024/the_platonic_representation_hypothesis/"><![CDATA[<p>Amidst the buzz around GPT-4o and Google I/O, it was easy to miss this fascinating philosophical paper from MIT. ‚Äú<a href="https://phillipi.github.io/prh/">The Platonic Representation Hypothesis</a>,‚Äù argues that AI models are converging towards a shared ‚Äúreality‚Äù. As they grow in size, their data representations across different modalities (images, text, etc.) become more aligned, echoing Plato‚Äôs ideal forms.</p> <p>üîç Highlights:</p> <p>‚Ä¢ Unified Representations: Larger models show more alignment, suggesting a common underlying reality and statistical model.</p> <p>‚Ä¢ Multimodal Efficiency: Combining data types boosts model performance and convergence.</p> <p>‚Ä¢ Revolutionary Potential: Easier cross-modal translation and adaptation could transform AI applications.</p>]]></content><author><name></name></author><category term="data-science"/><category term="AI"/><category term="MachineLearning"/><category term="DeepLearning"/><category term="MIT"/><category term="Research"/><category term="NeuralNetworks"/><summary type="html"><![CDATA[Exploring world representations in neural networks]]></summary></entry><entry><title type="html">Building Efficient Baselines in Minutes: EDA and Classification in Google Colab</title><link href="https://duncancalvert.github.io/blog/2023/building-efficient-baselines-in-minutes-eda-and-classification-in-google-colab/" rel="alternate" type="text/html" title="Building Efficient Baselines in Minutes: EDA and Classification in Google Colab"/><published>2023-11-26T23:23:35+00:00</published><updated>2023-11-26T23:23:35+00:00</updated><id>https://duncancalvert.github.io/blog/2023/building-efficient-baselines-in-minutes-eda-and-classification-in-google-colab</id><content type="html" xml:base="https://duncancalvert.github.io/blog/2023/building-efficient-baselines-in-minutes-eda-and-classification-in-google-colab/"><![CDATA[]]></content><author><name></name></author></entry></feed>